# ğŸ” RAGcraft â€” Progressive RAG Pipelines with LangGraph

A hands-on notebook series that builds a production-ready Retrieval-Augmented Generation (RAG) system from the ground up. Each notebook introduces one new concept on top of the last, so you can clearly see *why* each improvement matters.

Built with **LangChain**, **LangGraph**, **FAISS**, and **OpenAI**.

---

## ğŸ“š Notebook Series

| # | Notebook | What It Adds |
|---|----------|--------------|
| 1 | `1_basic_rag.ipynb` | Baseline RAG â€” chunk PDFs, embed with FAISS, retrieve + generate |
| 2 | `2_retrieval_refinement.ipynb` | Sentence-level decomposition â€” filter noisy chunks before generating |
| 3 | `3_retrieval_evaluator.ipynb` | LLM-based doc scorer â€” routes to `fail` if no good docs are found |
| 4 | `4_web_search_refinement.ipynb` | Web search fallback â€” fetches live results when the vector store falls short |
| 5 | `5_query_rewrite.ipynb` | Query rewriting â€” rewrites the user question into a better web search query |
| 6 | `6_ambiguous.ipynb` | Ambiguity detection â€” catches vague questions before wasting retrieval effort |

---

## ğŸ—ï¸ Architecture

Each notebook is a LangGraph `StateGraph` that evolves as the series progresses. By the final notebook, the full pipeline looks like this:

```
User Question
     â”‚
     â–¼
[Ambiguity Check] â”€â”€â–º Ambiguous? â†’ Return clarification request
     â”‚
     â–¼
[Vector Store Retrieval]
     â”‚
     â–¼
[LLM Doc Evaluator]  (scores each doc 0.0 â€“ 1.0)
     â”‚
  â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
PASS (â‰¥0.7)      FAIL (â‰¤0.3)
  â”‚                  â”‚
  â”‚            [Query Rewrite]
  â”‚                  â”‚
  â”‚           [Web Search Fallback]
  â”‚                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
   [Sentence Decomposer]
   (strip & filter retrieved text)
           â”‚
           â–¼
      [Generate Answer]
```

---

## âš™ï¸ Setup

**Prerequisites:** Python 3.10+, an OpenAI API key, and optionally a Tavily API key for web search.

```bash
pip install langchain langchain-community langchain-openai langgraph faiss-cpu pypdf pydantic tavily-python
```

Set your API keys:

```bash
export OPENAI_API_KEY="sk-..."
export TAVILY_API_KEY="tvly-..."   # needed for notebooks 4â€“6
```

Place your source PDFs in a `./documents/` folder:

```
documents/
  book1.pdf
  book2.pdf
  book3.pdf
```

---

## ğŸš€ Quickstart

Open the notebooks in order. Each one is self-contained and runnable top-to-bottom:

```bash
jupyter notebook 1_basic_rag.ipynb
```

Or run them all sequentially in JupyterLab.

---

## ğŸ”‘ Key Concepts Covered

- **Chunking & Embedding** â€” `RecursiveCharacterTextSplitter` + `text-embedding-3-large` + FAISS
- **Retrieval refinement** â€” sentence-level decomposition to keep only relevant sentences
- **LLM-as-judge** â€” structured scoring with Pydantic to evaluate retrieved docs
- **Conditional routing** â€” LangGraph edges that branch on retrieval quality
- **Web search fallback** â€” Tavily integration when local knowledge is insufficient
- **Query rewriting** â€” LLM rewrites vague user queries into precise search queries
- **Ambiguity detection** â€” early exit for questions that are too vague to answer reliably

---

## ğŸ› ï¸ Tech Stack

- [LangChain](https://python.langchain.com/) â€” document loading, splitting, chains
- [LangGraph](https://langchain-ai.github.io/langgraph/) â€” stateful multi-step pipelines
- [FAISS](https://github.com/facebookresearch/faiss) â€” fast vector similarity search
- [OpenAI](https://platform.openai.com/) â€” `gpt-4o-mini` for generation, `text-embedding-3-large` for embeddings
- [Tavily](https://tavily.com/) â€” real-time web search API

---

## ğŸ“ License

MIT
